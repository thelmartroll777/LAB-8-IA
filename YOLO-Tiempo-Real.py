#!/usr/bin/env python
# coding: utf-8

# Author:  
# Manuel Eugenio Morocho Cayamcela, PhD

# # YOLO en Tiempo Real: Detecci√≥n de Objetos
# 
# En este cuaderno de Jupyter exploraremos la tarea de la detecci√≥n de objetos en tiempo real utilizando YOLO (You Only Look Once), una t√©cnica avanzada de visi√≥n por computadora.
# 
# Aprenderemos a utilizar YOLO para identificar y localizar diversos objetos en im√°genes y secuencias de video. Esta habilidad es esencial en una amplia gama de aplicaciones, desde la conducci√≥n aut√≥noma hasta la vigilancia de seguridad, y representa uno de los avances m√°s emocionantes en el campo de la inteligencia artificial y la visi√≥n por computadora.
# 
# A lo largo de este tutorial, explorar√°s conceptos clave como:
# 
# - Detecci√≥n de objetos en tiempo real.
# - Configuraci√≥n de modelos YOLO pre-entrenados.
# - Interpretaci√≥n de resultados de detecci√≥n.
# - Aplicaciones pr√°cticas de la detecci√≥n de objetos.

# Utilizaremos el comando `!pip` para instalar dos paquetes de Python: `opencv-python` y `ultralytics`.
# 
# - `opencv-python`: Es un paquete para tareas de visi√≥n por computador en Python. Proporciona una variedad de funciones para el procesamiento de im√°genes y videos, incluyendo detecci√≥n de objetos, manipulaci√≥n de im√°genes y extracci√≥n de caracter√≠sticas.
# 
# - `ultralytics`: Es un paquete construido sobre PyTorch, que se enfoca principalmente en tareas de visi√≥n por computadora como detecci√≥n de objetos y clasificaci√≥n de im√°genes. Proporciona interfaces f√°ciles de usar para entrenar y evaluar modelos de aprendizaje profundo para estas tareas.
# 
# Al ejecutar este comando, est√°s instalando estos paquetes en tu entorno de Python para que puedas usarlos en tu c√≥digo.

# In[ ]:


# Instalamos las librer√≠as necesarias
get_ipython().run_line_magic('pip', 'install opencv-python ultralytics')


# Importamos las siguientes bibliotecas en Python:
# 
# 1. `ultralytics`: Esta es una biblioteca que proporciona una interfaz para usar modelos de detecci√≥n de objetos YOLO (You Only Look Once). Permite entrenar, evaluar y utilizar modelos de detecci√≥n de objetos de manera eficiente.
# 
# 2. `cv2` (OpenCV): Esta es una biblioteca popular para el procesamiento de im√°genes y videos en Python. Proporciona una amplia gama de funciones para trabajar con im√°genes y videos, incluyendo cargar im√°genes, realizar operaciones de procesamiento de im√°genes, y mostrar im√°genes en una ventana, entre otros.
# 
# 3. `math`: Este es un m√≥dulo est√°ndar de Python que proporciona funciones matem√°ticas comunes, como funciones trigonom√©tricas, logar√≠tmicas y aritm√©ticas.

# In[2]:


# Importamos las librer√≠as necesarias
from ultralytics import YOLO
import cv2
import math


# Para este tutorial, usaremos un modelo de YOLO preentrenado en una base de datos que contiene imagenes con sus respectivas cordenadas de cuadros delimitadores y etiquetas por cada objeto. La base de datos con la que el modelo fue preentrenado es COCO de Microsoft.

# In[3]:


# Cargamos el modelo YOLO pre-entrenado en COCO dataset
model = YOLO("yolo-Weights/yolov8n.pt")


# In[4]:


# Revisamos las clases que puede detectar el modelo
model.names


# In[ ]:


# Definimos una lista de nombres con todas las clases para identificar objetos detectados
classNames = [ "bird", "cat",
              "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe"
              ] # Aqu√≠ se enumeran todas las clases


# In[6]:


# Configuramos la captura de video desde la c√°mara
captura = cv2.VideoCapture(0) # Se abre la c√°mara por defecto

# Establecemos el ancho y alto de la imagen
captura.set(cv2.CAP_PROP_FRAME_WIDTH, 640) # Ancho de la imagen
captura.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # Alto de la imagen

# Iniciamos un bucle para procesar los fotogramas de la c√°mara
while True:
    success, img = captura.read() # Capturamos un fotograma

    # Realizamos la detecci√≥n de objetos en la imagen capturada (usando el modelo de YOLO pre-entrenado que cargamos anteriormente)
    results = model(img, stream=True)

   # Procesamos los resultados de la detecci√≥n
    for r in results:
        boxes = r.boxes

        # Iteramos sobre las cajas delimitadoras detectadas
        for box in boxes:
            # Obtenemos las coordenadas de la caja delimitadora
            x1, y1, x2, y2 = box.xyxy[0]
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # Convertimos a valores enteros

            # Dibujamos la caja delimitadora en la imagen
            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 1)

            # Obtenemos la confianza de la detecci√≥n
            confidence = math.ceil((box.conf[0]*100))/100
            print("Confidence --->",confidence)

            # Obtenemos el nombre de la clase detectada
            cls = int(box.cls[0])
            print("Class name -->", classNames[cls])

            # Mostramos el nombre de la clase junto a la caja delimitadora
            org = [x1, y1]
            font = cv2.FONT_HERSHEY_SIMPLEX
            fontScale = 1
            color = (255, 0, 0) # Color: Azul (formato BGR)
            thickness = 1
            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)

    # Mostramos la imagen con las detecciones
    cv2.imshow('Webcam', img)

    # Salimos del bucle si se presiona la tecla 'q'
    #if cv2.waitKey(1) == ord('q'):
    if cv2.waitKey(10) & 0xFF == ord('q'):
        break

# Liberamos la c√°mara y cerramos todas las ventanas
captura.release()
cv2.destroyAllWindows()


# # üß† Tarea: Despliegue del Sistema YOLOv8 en Jetson Nano 2GB
# 
# ## üìå Objetivo
# 
# Implementar un sistema de detecci√≥n en tiempo real utilizando YOLOv8 en una Jetson Nano 2GB conectada a la misma red local, con una c√°mara web USB.
# 
# ---
# 
# ## üîê Acceso a la Jetson Nano
# 
# Se les proporcionar√°:
# - Nombre de usuario
# - Direcci√≥n IP de la Jetson Nano
# - Contrase√±a
# 
# Usen la terminal de su computador para conectarse:
# 
# ```bash
# ssh usuario@ip_de_jetson

# # üìÇ Opci√≥n 1: Carrera de Matem√°tica
# 
# Clonar su repositorio desde GitHub y ejecutar el sistema directamente en la Jetson Nano.
# 
# ‚úÖ Pasos:
# 
# ### 1. Clonar el repositorio
# git clone https://github.com/usuario/repositorio.git
# 
# ### 2. Acceder al directorio del proyecto
# cd repositorio
# 
# ### 3. Crear entorno virtual e instalar dependencias
# python3 -m venv env
# source env/bin/activate
# pip install -r requirements.txt
# 
# ### 4. Ejecutar el sistema
# python YOLO-Tiempo-Real.py
# 

# # üì¶ Opci√≥n 2: Carrera de Ciencias Computacionales
# 
# Desplegar el sistema dentro de un contenedor Docker.
# 
# ‚úÖ Crear un archivo Dockerfile en el repositorio:

# ### Dockerfile
# FROM nvcr.io/nvidia/l4t-pytorch:r32.7.1-pth1.11-py3
# RUN apt-get update && apt-get install -y python3-pip libopencv-dev
# RUN pip3 install ultralytics opencv-python
# 
# COPY . /app
# WORKDIR /app
# 
# CMD ["python3", "YOLO-Tiempo-Real.py"]

# ## üê≥ Pasos para construir y ejecutar:
# 
# ### 1. Clonar su repositorio
# git clone https://github.com/usuario/repositorio.git
# cd repositorio
# 
# ### 2. Construir la imagen Docker
# sudo docker build -t yolov8-detector .
# 
# ### 3. Ejecutar el contenedor
# sudo docker run --rm -it --net=host --device=/dev/video0 yolov8-detector

# # üìù Entregable
# 
# - Confirmaci√≥n de funcionamiento con captura de pantalla o foto del sistema en ejecuci√≥n.
# - C√≥digo actualizado y funcional en su repositorio de GitHub.
